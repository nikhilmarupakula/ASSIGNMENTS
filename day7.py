# -*- coding: utf-8 -*-
"""day7

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C81GMnuuoF_wbQ_c-ta1PvgV6ebEgkdy
"""

import gensim
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import STOPWORDS
from nltk.stem import SnowballStemmer
import spacy
nlp = spacy.load('en_core_web_sm')
stemmer = SnowballStemmer('english')
text = "This is a sample text to demonstrate the use of Gensim for preprocessing."
tokens = simple_preprocess(text, deacc=True)
tokens = [token for token in tokens if token not in STOPWORDS]
stemmed_tokens = [stemmer.stem(token) for token in tokens]
doc = nlp(' '.join(stemmed_tokens))
lemmatized_tokens = [token.lemma_ for token in doc]
print("Original Text:", text)
print("Tokens:", tokens)
print("Stemmed Tokens:", stemmed_tokens)
print("Lemmatized Tokens:", lemmatized_tokens)